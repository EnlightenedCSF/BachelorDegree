\subsection{Анализ и сравнение альтернативных подходов к решению задачи трилатерации}

\subsubsection{Fingerprints}

Локационные «отпечатки пальцев» – набор признаков, присвоенных некоторой заведомо известной точке пространства \cite{elbes2013precise}.  В рамках задачи будем считать, что этим набором признаком является вектор из эталонных показателей RSSI, принятых от каждого из маячков.

Смысл алгоритма тогда будет состоять в следующем: пользователь в некоторый момент времени определяет ряд значений RSSI. Этот набор сравнивается с остальными с целью нахождения ближайшего «отпечатка», значения которого отличается минимально в рамках принятой метрики. И так как положение каждого из «отпечатка» заранее известно, становится возможным определить положение пользователя.

Данную задачу можно рассматривать как задачу классификации. Так, каждый отпечаток $FP_i$ в точке пространства $i (i=\overline{1,N})$ может быть представлен как $FP_i = \{ RSSI_1^{FP_i}, RSSI_2^{FP_i}, ..., RSSI_M^{FP_i} \}$, и соответствующая ему локация есть $L_i^{FP} = (X_i, Y_i)$.

Если представить положение пользователя как $T$, то ему сопоставим отпечаток $ S = \{ RSSI_1^T, RSSI_2^T, ..., RSSI_M^T \}$. После этого возможно найти дистанцию между $S$ и $FP_i$:
\begin{equation} \label{for:D}
    D^T_{FP_i} = \sqrt{ \sum_{j=1}^N ( RSSI_j^{FP_i} - RSSI_j^T )^2 }
\end{equation}

Будем считать $M$ количеством маячков, участвующих в рассмотрении. Теперь на основе расстояния можем вычислить вероятность того, что объект $Т$ находится около отпечатка $FP_i$ с измерениями $S$:
\begin{equation} \label{for:Prob}
    P(FP_i | S) = \frac{1}{ D^T_{FP_i} }
\end{equation}

Тогда правило определения локации можно сформулировать так: \textit{искомая точка – $i$ – если $P(FP_i | S) > P(FP_j | S)$, где $i,j = \overline{1,N}$. Ей соответствует локация $L_i^{FP}$.}

В реальности искомая позиция пользователя не является дискретной, и поэтому возникает необходимость интерполяции. Эта процедура осуществляется с помощью следующего преобразования, представленного ниже:
\[
    LT(x,y) = \sum_{i=1}^N P(FP_i | S) L_i^{FP}(x,y)
\]
, где $(x,y)$ - координаты $FP$.

В работе \cite{elbes2013precise} предложено дополнение для данного подхода, называемое Budgeted Dynamic Exclusion (BDE, "бюджетное динамическое исключение"). Суть модификации сводится к следующему: сравниваются показания $j$ и отпечаток $i$. Если некоторая пара значений RSSI, соответствующих одному и тому же маяку, меньше установленной константы, именуемой бюджетом, то эти два значения выкидываются из вектора с остальными значениями RSSI. Это приводит к тому, что оцениваемое формулой \ref{for:D} Евклидово расстояние уменьшается, и, соответственно, степень доверия, вычисляемая с помощью формулы \ref{for:Prob}, увеличивается.

Главным препятствием в работе такой системы является дифракция, отражение и рассеяние сигнала, принимаемого от маяков \cite{liu2007survey}. Кроме того, возникают сложности, связанные с выходом из строя маячков. Ведь в таком случае необходимо либо переснимать показания сигнал-шума от оставшихся маячков заново, либо предусмотреть дополнительную логику в приложении и работе алгоритма в целом. Оба способа достаточно затратны по времени.

Данный метод нахождения пользовательской локации был использован, например, на конференции GeekPicnic, проведенного в Москве в 2015г. \cite{web:habrGeekPicknic}. 

\subsubsection{Фильтр частиц (локализация по Монте-Карло)}

В рамках данного метода алгоритм генерирует сотни частиц, представляющих возможные положения пользователя. Вычисляются расстояния до маяков и учитываются значения их сигналов. На основании этих данных часть маячков фильтруется, то есть выходит из рассмотрения, а оставшаяся часть участвует в дальнейших вычислениях. Это происходит в результате обновления весов, присвоенных каждой из частиц.

Проблему локализации можно сформулировать как проблему определения апостериорной вероятности  $p(x_k | z_{1:k})$. Начальное распределение $p(x_0)$ считается равномерным по всем возможным локациям $[x y]^T$.

Рассматривая локализацию по Монте-Карло, требуемое распределение \\$p(x_k | z_{1:k})$ может быть представлено в виде множества взвешенных значений:
\[
    S_k = \{ x^i, \omega^i \}, i = 0,1,2,...,N_p
\]
, где $\omega^i$ - вес частицы - представляет собой фактор важности, для которого выполняется равенство $\sum_{i=1}^{N_p} \omega_i = 1$. Апостериорная вероятность может быть аппроксимирована с помощью следующего выражения:
\[
    p(x_k | z_k) \approx \frac{1}{N_p} \sum \delta (x_k - x_k^i)
\]
, где $\delta$ - дельта-функция Дирака. Для достаточно большого $N_p$ аппроксимация отклоняется от истинного значения искомого распределения незначительно.

Алгоритм функционирует в несколько стадий:
\begin{enumerate}
    \item
    \textbf{Предсказание}. На этом этапе апостериорное распределение \\$p(x_k | x_{k-1}, u_{k-1})$ в момент времени $k$ предсказывается на основании состояния $p(x_{k-1} | z_{1:k-1})$ и управляющего вектора $u_{k-1}$. Множество частиц $S_{k-1}$ соответствует состоянию $x_{k-1}$. Вектор $u_{k-1}$ должен быть применен к каждой частице из $S_{k-1}$. Это дает новый набор $S'_k = x'^i, \omega'^i, i=0,1,2,..., N_p$. Заметим, что $\omega'^i = \omega^i$.
    \item
    \textbf{Обновление}. На этом шаге принимается во внимание модель измерений: каждая частица из $S'_k$ изменяет вес на основании степени схожести с $p(z_k | x^i_k), i=0,1,2,...,N_p$. После этого образуется новый набор частиц $S_k$.
    \item
    \textbf{Вырождение}. После нескольких итераций большинство частиц имеют незначительный вес, и лишь немногие из них вносят значительный вклад в вычисления. Это стало причиной разработок многих алгоритмов ресэмплинга, позволяющих выделить только необходимую часть частиц. Чтобы избежать накладных расходов на ресэмплинг во время каждой из итераций, зачастую вычисляется Effective Sample Size, ESS. На основании этого функционала, ресэмплинг применяется лишь в случае, когда величина ESS опускается ниже определенного порога. Ресемплинг зачастую, помима отсева незначащих частиц, дуплицирует те, значения весов которых значительны.
    \begin{align}
        cv_t^2 &= \frac{var(\omega_t^i)}{ E^2(\omega_t^i) } = \frac{1}{N_p} \sum_{i=1}^{N_p} (N_p \omega^i - 1)^2 \notag \\
        ESS_t &= \frac{N_p}{(1+cv_t^2)} \notag
    \end{align}
\end{enumerate}